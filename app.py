import streamlit as st
import os
import json
import re
import requests
from huggingface_hub import InferenceClient
from datetime import datetime
from opencc import OpenCC
cc = OpenCC('s2t')  # s2t: simplified to traditional



def hf_translate(api_url, text, src_lang=None, tgt_lang=None):
    payload = {
        "inputs": text,
        "parameters": {},
        "options": {"wait_for_model": True}
    }
    if src_lang and tgt_lang:
        payload["parameters"]["src_lang"] = src_lang
        payload["parameters"]["tgt_lang"] = tgt_lang

    response = requests.post(api_url, headers=HEADERS, json=payload)
    if response.status_code != 200:
        raise Exception(f"API error {response.status_code}: {response.text}")
    result = response.json()
    return result[0]["translation_text"]

def get_word_info(word):
    resp = requests.get(f"https://api.dictionaryapi.dev/api/v2/entries/en/{word}")
    if resp.status_code != 200:
        return None
    data = resp.json()[0]
    # åªå–ç¬¬ä¸€ç§è¯æ€§ã€å®šä¹‰å’Œä¾‹å¥
    meaning = data["meanings"][0]
    return {
        "partOfSpeech": meaning["partOfSpeech"],
        "definition": meaning["definitions"][0]["definition"],
        "example": meaning["definitions"][0].get("example", "")
    }

def query_jisho(word):
    url = f"https://jisho.org/api/v1/search/words?keyword={word}"
    r = requests.get(url)
    if r.status_code != 200:
        return None
    data = r.json()
    if not data["data"]:
        return None
    entry = data["data"][0]
    japanese = entry["japanese"][0]
    senses = entry["senses"][0]

    # æ”¹ç‚ºå˜—è©¦æ‹¿ç¬¬ä¸€å€‹ä¾‹å¥ï¼ˆæ—¥æ–‡ï¼‰ï¼Œå¦‚æœæ²’æœ‰å°±ç©ºå­—ä¸²
    example_sentence = ""
    if "sentences" in entry and len(entry["sentences"]) > 0:
        example_sentence = entry["sentences"][0].get("ja", "")
    else:
        # æœ‰äº›å­—å…¸çµæœæœƒæ”¾åœ¨ senses çš„ "links" æˆ–å…¶å®ƒæ¬„ä½ï¼Œè¦–éœ€æ±‚å†æ“´å±•
        example_sentence = ""

    return {
        "word": japanese.get("word", ""),
        "reading": japanese.get("reading", ""),
        "part_of_speech": senses.get("parts_of_speech", []),
        "english_definitions": senses.get("english_definitions", []),
        "example_sentence": example_sentence
    }

def generate_example_sentence(word):
    prompt = (
        f"è«‹ç”¨å–®è© '{word}' é€ ä¸€å€‹ç°¡å–®çš„æ—¥æ–‡ä¾‹å¥ï¼Œä¸¦é™„ä¸Šä¸­æ–‡ç¿»è­¯ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
        "ä¾‹å¥ï¼ˆæ—¥æ–‡ï¼‰ï¼š...\n"
        "ä¾‹å¥ï¼ˆä¸­æ–‡ï¼‰ï¼š..."
    )
    try:
        response = client.chat.completions.create(
            model="Qwen/Qwen2.5-1.5B-Instruct",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=200,
            temperature=0.7,
        )
        text = response.choices[0].message.content.strip()
        return text
    except Exception as e:
        return f"ç”Ÿæˆä¾‹å¥æ™‚å‡ºéŒ¯ï¼š{e}"


# === Hugging Face Token ===
HF_TOKEN = st.secrets["HF_TOKEN"]
API_JA_EN = "https://api-inference.huggingface.co/models/facebook/mbart-large-50-many-to-many-mmt"
API_EN_ZH = "https://api-inference.huggingface.co/models/Helsinki-NLP/opus-mt-en-zh"
HEADERS = {"Authorization": f"Bearer {HF_TOKEN}"}

client = InferenceClient(token=HF_TOKEN)


# === åˆå§‹åŒ–ç‹€æ…‹ ===

if "article_text" not in st.session_state:
    st.session_state.article_text = ""
if "questions" not in st.session_state:
    st.session_state.questions = []
if "user_answers" not in st.session_state:
    st.session_state.user_answers = []
if "submitted" not in st.session_state:
    st.session_state.submitted = False
if "explanation" not in st.session_state:
    st.session_state.explanation = None
if "show_explanation" not in st.session_state:
    st.session_state.show_explanation = False



explanation=""
# === é é¢æ¨™é¡Œ ===
st.title("ğŸ“– æ—¥æ–‡é–±è®€ç†è§£ç·´ç¿’å¹³å°")

# === è¼¸å…¥æ–‡ç«  ===
st.text_area("è«‹è²¼å…¥æ—¥æ–‡æ–‡ç« ï¼š", height=200, key="article_text")

# === é¡Œç›®ç”Ÿæˆ ===
if st.button("ç”Ÿæˆé¡Œç›®"):
    prompt = (
        "ã‚ãªãŸã¯æ—¥æœ¬èªã®å…ˆç”Ÿã§ã™ã€‚ä»¥ä¸‹ã®æ–‡ç« ã®ç†è§£åŠ›ã‚’è©¦ã™è³ªå•ã‚’3å•ä½œæˆã—ã¦ãã ã•ã„ã€‚è³ªå•å†…å®¹ã¯æ–‡ç« å†…ã®æƒ…å ±ã®ã¿ã‚’ä½¿ã†ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚ãã‚Œãã‚Œã®è³ªå•ã«å¯¾ã™ã‚‹ç­”ãˆã¯1ã¤ã ã‘ã«ãªã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚\n"
        "å‡ºåŠ›ã¯å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã§è¿”ç­”ã—ã¦ãã ã•ã„ï¼š\n"
        "{\n"
        '  "questions": [\n'
        '    {"question":"...", "options":["...","...","...","..."], "answer":"...", "explanation":"..."},\n'
        "    ... åˆè¨ˆ3å• ...\n"
        "  ]\n"
        "}\n\n"
        f"æ–‡ç« ï¼š{st.session_state.article_text}"
    )

    with st.spinner("é¡Œç›®ç”Ÿæˆä¸­..."):
        try:
            response = client.chat.completions.create(
                model="Qwen/Qwen2.5-1.5B-Instruct",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000,
                temperature=0.7,
            )
        except Exception as e:
            st.error(f"æ¨¡å‹å‘¼å«éŒ¯èª¤ï¼š{e}")
            st.stop()

        raw_output = response.choices[0].message.content
        #st.markdown("##### ğŸ“¦ æ¨¡å‹è¼¸å‡ºï¼ˆå¯æŸ¥çœ‹æ ¼å¼ï¼‰")
        #st.code(raw_output)

        json_match = re.search(r"\{.*\}", raw_output, re.DOTALL)
        if not json_match:
            st.error("âŒ æ‰¾ä¸åˆ° JSON æ ¼å¼é¡Œç›®ï¼Œè«‹å˜—è©¦é‡æ–°ç”Ÿæˆ")
            st.stop()

        json_text = json_match.group(0)
        try:
            data = json.loads(json_text)
        except json.JSONDecodeError as e:
            st.error(f"JSON è§£ç¢¼å¤±æ•—ï¼š{e}")
            st.code(json_text)
            st.stop()

        st.session_state.questions = data.get("questions", [])
        st.session_state.user_answers = ["" for _ in st.session_state.questions]
        st.session_state.submitted = False
        st.session_state.explanation = None
        
        # === é¡å¤–ï¼šç”Ÿæˆè§£èªªå…§å®¹ä¸¦æš«å­˜åˆ° session_state
        explain_prompt = (
            f"ä½ æ˜¯ä¸€ä½æ“…é•·èªè¨€æ•™å­¸çš„å°ˆå®¶ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡è©³ç´°è§£é‡‹ä»¥ä¸‹æ—¥æ–‡æ–‡ç« çš„å…§å®¹ï¼ŒåŒ…æ‹¬ï¼š\n"
            f"1. æ–‡ç« ä¸»æ—¨æ˜¯ä»€éº¼ï¼Ÿ\n"
            f"2. æœ‰å“ªäº›é‡è¦èªæ³•ï¼Ÿ\n"
            f"3. æ–‡ç« ä¸­çš„é—œéµè©å½™æœ‰å“ªäº›æ„æ€ï¼Ÿ\n"
            f"4. å¦‚æœæœ‰é›£å¥ï¼Œå¦‚ä½•ç†è§£ï¼Ÿ\n\n"
            f"æ—¥æ–‡æ–‡ç« å¦‚ä¸‹ï¼š{st.session_state.article_text}"
        )

        try:
            explain_response = client.chat.completions.create(
                model="Qwen/Qwen2.5-1.5B-Instruct",
                messages=[{"role": "user", "content": explain_prompt}],
                max_tokens=800,
                temperature=0.7,
            )
            st.session_state.explanation = explain_response.choices[0].message.content
            st.session_state.explanation = cc.convert(st.session_state.explanation)
        except Exception as e:
            st.session_state.explanation = f"âš ï¸ ç„¡æ³•ç”Ÿæˆä¸­æ–‡è§£èªªï¼š{e}"
    
    st.session_state.show_explanation = False
        

# === é¡¯ç¤ºé¡Œç›®èˆ‡ä½œç­” ===
if st.session_state.questions:
    st.subheader("ğŸ“ ä½œç­”å€")
    for i, q in enumerate(st.session_state.questions):
        st.markdown(f"#### Q{i+1}: {q['question']}")
        st.session_state.user_answers[i] = st.radio(
            f"é¸æ“‡ç­”æ¡ˆ {i+1}",
            options=q["options"],
            index=q["options"].index(st.session_state.user_answers[i]) if st.session_state.user_answers[i] in q["options"] else 0,
            key=f"q_{i}"
        )

    if st.button("æäº¤ç­”æ¡ˆ"):
        st.session_state.show_explanation = True
        score = sum(
            1 for i, q in enumerate(st.session_state.questions)
            if st.session_state.user_answers[i] == q["answer"]
        )
        st.success(f"ğŸ‰ ä½ ç¸½å…±ç­”å° {score}/{len(st.session_state.questions)} é¡Œï¼")

        for i, q in enumerate(st.session_state.questions):
            is_correct = st.session_state.user_answers[i] == q["answer"]
            color = "âœ…" if is_correct else "âŒ"
            st.markdown(f"**{color} Q{i+1} æ­£è§£ï¼š** {q['answer']} â€” {q['explanation']}")        
        

        # å„²å­˜æˆç¸¾åˆ° JSON
        history = []
        record_file = "score_history.json"
        if os.path.exists(record_file):
            with open(record_file, "r", encoding="utf-8") as f:
                history = json.load(f)

        new_record = {
        "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "score": score,
        "total": len(st.session_state.questions),
        "questions": [q["question"] for q in st.session_state.questions],
        "answers": st.session_state.user_answers,
        "correct_answers": [q["answer"] for q in st.session_state.questions],
        "explanations": [q["explanation"] for q in st.session_state.questions],
        "article_explanation": st.session_state.explanation
    }
        

        history.append(new_record)

        with open(record_file, "w", encoding="utf-8") as f:
            json.dump(history, f, indent=2, ensure_ascii=False)

        st.info("ğŸ“ æˆç¸¾å·²å„²å­˜åˆ° `score_history.json`")
        
if st.session_state.show_explanation and st.session_state.explanation:
    st.markdown("### ğŸ§  æ•´ç¯‡æ–‡ç« çš„ä¸­æ–‡è¬›è§£")
    st.write(st.session_state.explanation)


# --- å–®å­—ç¿»è­¯åŠŸèƒ½å€å¡Š ---
st.markdown("---")
st.subheader("ğŸŒ æ—¥æ–‡ âœ ä¸­æ–‡ ç¿»è­¯å™¨")

input_text = st.text_input("è«‹è¼¸å…¥æ—¥æ–‡å–®å­—æˆ–çŸ­èªï¼š", key="translate_input")

if st.button("ç¿»è­¯"):
    with st.spinner("ç¿»è­¯ä¸­...è«‹ç¨å€™"):
        try:
            # 1ï¸âƒ£ æ—¥ âœ è‹±ï¼ˆmbart éœ€è¦æŒ‡å®šèªè¨€ä»£ç¢¼ï¼‰
            en_result = hf_translate(API_JA_EN, input_text, src_lang="ja_XX", tgt_lang="en_XX")

            # 2ï¸âƒ£ è‹± âœ ä¸­æ–‡ï¼ˆHelsinki æ¨¡å‹ä¸éœ€è¦èªè¨€ä»£ç¢¼ï¼‰
            zh_result = hf_translate(API_EN_ZH, en_result)
            zh_result = cc.convert(zh_result)  # ç°¡è½‰ç¹

            # é¡¯ç¤ºçµæœ
            st.success("âœ… ç¿»è­¯æˆåŠŸï¼")
            st.markdown(f"""
            - åŸå§‹æ—¥æ–‡ï¼š`{input_text}`
            - ç¿»è­¯ä¸­æ–‡ï¼š`{zh_result}`
            """)

            # å–®å­—è©å½™è³‡è¨Š
            info = query_jisho(input_text)
            if info:
                st.write(f"å–®è©ï¼š{info['word']}ï¼ˆè®€éŸ³ï¼š{info['reading']}ï¼‰")
                st.write(f"è©æ€§ï¼š{', '.join(info['part_of_speech'])}")
                st.write(f"è‹±æ–‡å®šç¾©ï¼š{', '.join(info['english_definitions'])}")
                if info['example_sentence']:
                    st.write(f"ä¾‹å¥ï¼ˆæ—¥æ–‡ï¼‰ï¼š{info['example_sentence']}")
                else:
                    # ç”¨ Qwen ç”Ÿæˆä¾‹å¥
                    example = generate_example_sentence(input_text)
                    st.markdown("ğŸ”¹ **å–®è©ä½¿ç”¨ä¾‹å¥**")
                    lines = example.splitlines()
                    ja_line = ""
                    zh_line = ""

                    for line in lines:
                        if "ä¾‹å¥ï¼ˆæ—¥æ–‡ï¼‰" in line:
                            ja_line = line.replace("ä¾‹å¥ï¼ˆæ—¥æ–‡ï¼‰ï¼š", "").strip()
                        elif "ä¾‹å¥ï¼ˆä¸­æ–‡ï¼‰" in line:
                            zh_line = line.replace("ä¾‹å¥ï¼ˆä¸­æ–‡ï¼‰ï¼š", "").strip()
                    zh_line = cc.convert(zh_line)  # åŠ é€™è¡Œå³å¯

                    # é¡¯ç¤º
                    if ja_line:
                        st.write(f"æ—¥æ–‡ï¼š{ja_line}")
                    if zh_line:
                        st.write(f"ä¸­æ–‡ï¼š{zh_line}")
            else:
                st.write("æ‰¾ä¸åˆ°è©²å–®è©çš„è©å½™è³‡è¨Š")
                example = generate_example_sentence(input_text)
                st.markdown("ğŸ”¹ **Qwenç”Ÿæˆçš„ä¾‹å¥**")
                st.write(example)

        except Exception as e:
            st.error("âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š")
            st.exception(e)

   # === é¡¯ç¤ºæ­·å²ç´€éŒ„ ===
st.markdown("---")
st.subheader("ğŸ“Š æ­·å²æˆç¸¾ç´€éŒ„")

if os.path.exists("score_history.json"):
    with open("score_history.json", "r", encoding="utf-8") as f:
        history_data = json.load(f)
    if history_data:
        for idx, record in enumerate(reversed(history_data[-10:])):
            with st.expander(f"ğŸ—“ï¸ {record['date']} - åˆ†æ•¸ï¼š{record['score']}/{record['total']}"):
                for i in range(len(record["questions"])):
                    st.markdown(f"**Q{i+1}:** {record['questions'][i]}")
                    if record['answers'][i]!=record['correct_answers'][i]:
                        st.markdown(f"âŒ ä½ çš„ç­”æ¡ˆï¼š{record['answers'][i]}")
                        st.markdown(f"âœ… æ­£ç¢ºç­”æ¡ˆï¼š{record['correct_answers'][i]}")
                    else:
                        st.markdown(f"ğŸ‘‰ ä½ çš„ç­”æ¡ˆï¼š{record['answers'][i]}")
                        st.markdown(f"âœ… æ­£ç¢ºç­”æ¡ˆï¼š{record['correct_answers'][i]}")
                    st.markdown(f"ğŸ“˜ è§£èªªï¼š{record['explanations'][i]}")
                    st.markdown("---")
    else:
        st.write("ç›®å‰å°šç„¡æˆç¸¾ç´€éŒ„ã€‚")
else:
    st.write("å°šæœªç”¢ç”Ÿä»»ä½•æˆç¸¾ç´€éŒ„ã€‚")